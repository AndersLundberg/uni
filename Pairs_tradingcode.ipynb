{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import pandas_datareader as pdr\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import math\n",
    "import itertools\n",
    "from itertools import compress\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "from datetime import datetime\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from sklearn.preprocessing import StandardScaler # for standardizing the Data\n",
    "from sklearn.decomposition import PCA # for PCA calculation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "matplotlib.get_configdir()\n",
    "plt.style.use('science')\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2015, 1, 1)\n",
    "end = datetime(2021, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2015, 1, 1)\n",
    "end = datetime(2021, 1, 1)\n",
    "\n",
    "tickers = ['LECBF', 'NUPMF', 'ELKMF', 'OBNNF', 'DGMLF', 'RMLRF', 'DRD', 'RNGTF', 'WDOFF', 'CSFFF', 'HL-PB', 'SVLKF', 'SVM', 'JINFF', 'TORXF', 'DPMLF', 'NGD', 'PMNXF', 'OGDCF', 'SILV', 'OCANF', 'SAND', 'STBMF', 'STBMY', 'KNTNF', 'CENX', 'SA', 'RGRNF', 'FSM', 'HCHDF', 'TGCDF', 'IAG', 'KALU', 'HBM', 'CELTF', 'MAG', 'OR', 'FTMNF', 'CSTM', 'PVG', 'CDE', 'EGO', 'EQX', 'HMY', 'BVN', 'TRQ', 'NG', 'CAGDF', 'AGI', 'HL', 'SSRM', 'AWCMF', 'AWCMY', 'AG', 'SCEXF', 'AA', 'AUY', 'OZMLF', 'EDVMF', 'KZMYY', 'BTG', 'CAHPF', 'NESRF', 'PAAS', 'RGLD', 'LUNMF', 'ALMMF', 'GFI', 'ACH', 'KGC', 'NHYDY', 'NHYKF', 'AU', 'JIAXF', 'KL', 'AUCOY', 'FNLPF', 'IMPUY', 'IMPUF', 'SBSW', 'FQVLF', 'AEM', 'NCMGY', 'NCMGF', 'WPM', 'ANFGF', 'FNV', 'OPYGY', 'AGPPF', 'ANGPY', 'GOLD', 'ZIJMY', 'FCX', 'ZIJMF', 'NEM', 'SCCO','GLD', 'IAU', 'GLDM', 'SGOL', 'BAR','SLV', 'SIVR', 'AGQ', 'ZSL','CPER']\n",
    "df = pdr.get_data_yahoo(tickers, start, end)['Adj Close']\n",
    "#df.to_csv('C:/Users/ander/Dropbox/Abe finance/Vol.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = ['^GSPC','^DJI','^IXIC','GC=F','^VIX', '^IRX']\n",
    "bm = pdr.get_data_yahoo(benchmark, start, end)['Adj Close']\n",
    "bm.to_csv('C:/Users/ander/Dropbox/Abe finance/Benchm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 120\n",
    "#print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "cap=pd.read_excel(\"Cap.xlsx\")\n",
    "close=pd.read_csv(\"Close.csv\", index_col=0)\n",
    "vol=pd.read_csv(\"Vol.csv\", index_col=0)\n",
    "bm=pd.read_csv(\"Benchm.csv\", index_col=0)\n",
    "short_cost=pd.read_excel(\"Short-fees.xlsx\")\n",
    "short_cost=(1+short_cost.iloc[:,0:37]/100)**(1/365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover=vol.iloc[:,0:85]*close.iloc[:,0:85]\n",
    "# find rows that meet your criteria and average\n",
    "avgturnover = turnover.loc['2019-10-01':'2019-12-31', :].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stonks=[]\n",
    "for i in range(0,len(avgturnover)):\n",
    "    if avgturnover[i]>1000000 and cap.iloc[0,i]>1000:\n",
    "        stonks.append(avgturnover.index[i])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETF=['GLD', 'IAU', 'GLDM', 'SGOL', 'BAR','SLV']\n",
    "df=close.loc[:,stonks+ETF]\n",
    "df = df.dropna(how='any', axis=1)\n",
    "df = (np.log(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationarity_test(X, cutoff=0.01):\n",
    "    # H_0 in adfuller is unit root exists (non-stationary)\n",
    "    # We must observe significant p-value to convince ourselves that the series is stationary\n",
    "    pvalue = adfuller(X)[1]\n",
    "    if pvalue < cutoff:\n",
    "        print('p-value = ' + str(pvalue) + ' The series ' + X.name +' is likely stationary.')\n",
    "    else:\n",
    "        print(X.name +' ' + str(round(pvalue,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df.columns)):\n",
    "    if df.index.get_loc(df.iloc[:,i].first_valid_index())==0:\n",
    "        stationarity_test(df.iloc[:df.index.get_loc('2019-12-31'),i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cointegrated_pairs(data):\n",
    "    n = data.shape[1]\n",
    "    score_matrix = np.zeros((n, n))\n",
    "    pvalues= []\n",
    "    keys = data.keys()\n",
    "    pairs = []\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            S1 = data.iloc[max(df.index.get_loc(df.iloc[:,i].first_valid_index()),df.index.get_loc(df.iloc[:,j].first_valid_index())):df.index.get_loc('2019-12-31'),i]\n",
    "            S2 = data.iloc[max(df.index.get_loc(df.iloc[:,i].first_valid_index()),df.index.get_loc(df.iloc[:,j].first_valid_index())):df.index.get_loc('2019-12-31'),j]\n",
    "            result = coint(S1, S2,trend='ct')   #SKAL RETTES TILBAGE;HVIS DEN SKAL KÃ˜RES IGEN!!!\n",
    "            score = result[0]\n",
    "            pvalue = result[1]\n",
    "            score_matrix[i, j] = score\n",
    "            if pvalue < 0.05:\n",
    "                pairs.append(keys[i]+\" \" +keys[j])\n",
    "                pvalues.append(pvalue)\n",
    "    return score_matrix, pvalues, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, pvalues, pairs = find_cointegrated_pairs(df.iloc[:1+df.index.get_loc('2019-12-31'),:])\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spread and std. errors are estimated in the periode until 2020-01-20\n",
    "beta=[]\n",
    "alpha=[]\n",
    "spreaddf=pd.DataFrame(index=df.index)\n",
    "for i in range(0,len(pairs)):\n",
    "    firstobs=0#max(df.index.get_loc(df.loc[:,pairs[i][0]].first_valid_index()),df.index.get_loc(df.loc[:,pairs[i][1]].first_valid_index()))\n",
    "    obs=len(df)-firstobs\n",
    "    if firstobs==0:\n",
    "        firstobs= None\n",
    "    else:\n",
    "        firstobs= max(df.loc[:,pairs[i][0]].first_valid_index(),df.loc[:,pairs[i][1]].first_valid_index())\n",
    "    \n",
    "\n",
    "    S1=df.loc[firstobs:,pairs[i].split(' ')[0]].to_numpy()\n",
    "    S1= sm.add_constant(df.loc[firstobs:,pairs[i].split(' ')[0]]).to_numpy()\n",
    "    S1_partial=df.loc[firstobs:'2020-01-02',pairs[i].split(' ')[0]].to_numpy()\n",
    "    S1_partial = sm.add_constant(df.loc[firstobs:'2020-01-02',pairs[i].split(' ')[0]]).to_numpy()\n",
    "    S2_partial=df.loc[firstobs:'2020-01-02',pairs[i].split(' ')[1]].to_numpy()\n",
    "    S2_partial=S2_partial.reshape(len(S2_partial),1)\n",
    "    results = sm.OLS(S2_partial, S1_partial).fit()\n",
    "    spread = df.loc[:,pairs[i].split(' ')[1]] - np.dot(S1,results.params)\n",
    "    spreaddf[pairs[i].split(' ')[0] + \" \"+ pairs[i].split(' ')[1]] = spread \n",
    "    beta.append(results.params[1])\n",
    "    alpha.append(results.params[0])\n",
    "\n",
    "#Normalising the spreads\n",
    "zdf=[]\n",
    "for i in range(0,len(pairs)):\n",
    "    zdf.append(spreaddf.iloc[:df.index.get_loc('2020-01-02'),i].std())\n",
    "\n",
    "spreaddf=spreaddf.div(zdf)\n",
    "oldpairsspread=spreaddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairstable=pd.DataFrame(index=pairs)\n",
    "pairstable['Alpha']=alpha\n",
    "pairstable['Beta']=beta\n",
    "pairstable['p-value']=pvalues\n",
    "pairstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Selection crit ########################\n",
    "#Sum of  squared diff\n",
    "sortpairs=pd.DataFrame(((spreaddf.iloc[:df.index.get_loc('2020-01-02'),:].diff()) ** 2).sum())\n",
    "#0-Crossings\n",
    "crossing=[((np.array(spreaddf.iloc[:df.index.get_loc('2020-01-02')-1,i])*np.array(spreaddf.iloc[1:df.index.get_loc('2020-01-02'),i]))<0).sum() for i in range(0,len(pairs))]\n",
    "sortpairs['NZC']=crossing\n",
    "\n",
    "#Selecting pairs that are not in the worst decile of either category\n",
    "sortpairs['SSD Rank'] = pd.qcut(sortpairs.iloc[:,0], 4,labels = False) \n",
    "sortpairs['NZC Rank'] = pd.qcut(sortpairs['NZC'], 4,labels = False) \n",
    "\n",
    "l=sortpairs['NZC Rank']>0\n",
    "a=sortpairs['SSD Rank']<3\n",
    "pairs=list(compress(pairs, l&a))\n",
    "\n",
    "beta_temp=[]\n",
    "for i in range(0,len(pairs)):\n",
    "    beta_temp.append(beta[spreaddf.columns.get_loc(pairs[i])])\n",
    "spreaddf=spreaddf.loc[:,pairs]\n",
    "beta=beta_temp\n",
    "temp_df=pd.DataFrame(index=df.index, columns=spreaddf.columns)\n",
    "temp_df.iloc[:,:]=np.array(beta).reshape(1,len(pairs))\n",
    "beta_norm=temp_df\n",
    "spread_norm=spreaddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lav tabel med, estimater Par, (alpha + beta), Rank i SSD og NZC?\n",
    "pairstable=pd.concat([pairstable, sortpairs], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairstable.round({'Alpha': 2, 'Beta': 3,'p-value':3,0:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling spread\n",
    "rollstart='2017-01-04'\n",
    "\n",
    "betarollm=pd.DataFrame(index=df.index, columns=spreaddf.columns)\n",
    "spreaddfroll=pd.DataFrame(index=df.index)\n",
    "zdfroll=pd.DataFrame(index=df.index, columns=spreaddf.columns)\n",
    "\n",
    "for i in range(0,len(pairs)):\n",
    "    S1=df.loc[:,pairs[i].split(' ')[0]].to_numpy()\n",
    "    S1= sm.add_constant(df.loc[:,pairs[i].split(' ')[0]]).to_numpy()\n",
    "    S2=(df.loc[:,pairs[i].split(' ')[1]].to_numpy())\n",
    "    S2=S2.reshape(len(S2),1)\n",
    "            \n",
    "    S1_partial=df.loc[:rollstart,pairs[i].split(' ')[0]].to_numpy()\n",
    "    S1_partial = sm.add_constant(df.loc[:rollstart,pairs[i].split(' ')[0]]).to_numpy()\n",
    "    S2_partial=df.loc[:rollstart,pairs[i].split(' ')[1]].to_numpy()\n",
    "    S2_partial=S2_partial.reshape(len(S2_partial),1)\n",
    "    results = sm.OLS(S2_partial, S1_partial).fit()\n",
    "    spread = df.loc[:,pairs[i].split(' ')[1]] - (np.dot(S1,results.params))\n",
    "    spreaddfroll[pairs[i].split(' ')[0] + \" \"+ pairs[i].split(' ')[1]] = spread \n",
    "    betarollm.iloc[:,i]=(results.params[1])\n",
    "    zdfroll.iloc[:,i]=spreaddfroll.iloc[:df.index.get_loc('2019-12-31')+1,i].std()\n",
    "        \n",
    "    for j in range(df.index.get_loc(rollstart), len(df)):\n",
    "        results = sm.OLS(S2[0:(j+1)], S1[0:(j+1)]).fit()\n",
    "        spread = S2[:(j+1)]-(np.dot(S1[:(j+1)],results.params)).reshape(j+1,1)\n",
    "        spreaddfroll.iloc[j,i] = spread[-1]\n",
    "        betarollm.iloc[j,i]=(results.params[1])\n",
    "        zdfroll.iloc[j,i]=spreaddfroll.iloc[:j+1,i].std()      \n",
    "\n",
    "#Normalising the spreads\n",
    "spreaddfroll=spreaddfroll/zdfroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling spread\n",
    "rollstart='2020-01-02'\n",
    "\n",
    "betaroll=pd.DataFrame(index=df.index, columns=spreaddf.columns)\n",
    "spreaddfroll=pd.DataFrame(index=df.index)\n",
    "zdfroll=pd.DataFrame(index=df.index, columns=spreaddf.columns)\n",
    "\n",
    "for i in range(0,len(pairs)):\n",
    "    S1=df.loc[:,pairs[i].split(' ')[0]].to_numpy()\n",
    "    S1= sm.add_constant(df.loc[:,pairs[i].split(' ')[0]]).to_numpy()\n",
    "    S2=(df.loc[:,pairs[i].split(' ')[1]].to_numpy())\n",
    "    S2=S2.reshape(len(S2),1)\n",
    "            \n",
    "    S1_partial=df.loc[:rollstart,pairs[i].split(' ')[0]].to_numpy()\n",
    "    S1_partial = sm.add_constant(df.loc[:rollstart,pairs[i].split(' ')[0]]).to_numpy()\n",
    "    S2_partial=df.loc[:rollstart,pairs[i].split(' ')[1]].to_numpy()\n",
    "    S2_partial=S2_partial.reshape(len(S2_partial),1)\n",
    "    results = sm.OLS(S2_partial, S1_partial).fit()\n",
    "    spread = df.loc[:,pairs[i].split(' ')[1]] - (np.dot(S1,results.params))\n",
    "    spreaddfroll[pairs[i].split(' ')[0] + \" \"+ pairs[i].split(' ')[1]] = spread \n",
    "    betaroll.iloc[:,i]=(results.params[1])\n",
    "    zdfroll.iloc[:,i]=spreaddfroll.iloc[:df.index.get_loc('2019-12-31')+1,i].std()\n",
    "        \n",
    "    for j in range(df.index.get_loc(rollstart), len(df)):\n",
    "        results = sm.OLS(S2[0:(j+1)], S1[0:(j+1)]).fit()\n",
    "        spread = S2[:(j+1)]-(np.dot(S1[:(j+1)],results.params)).reshape(j+1,1)\n",
    "        spreaddfroll.iloc[j,i] = spread[-1]\n",
    "        betaroll.iloc[j,i]=(results.params[1])\n",
    "        zdfroll.iloc[j,i]=spreaddfroll.iloc[:j+1,i].std()      \n",
    "\n",
    "#Normalising the spreads\n",
    "spreaddfroll=spreaddfroll/zdfroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Half life exp\n",
    "spread_norm.iloc[:df.index.get_loc('2019-12-31')+1,:]\n",
    "\n",
    "z_lag = spread_norm.iloc[:df.index.get_loc('2019-12-31')+1,:].shift()\n",
    "z_ret=spread_norm.iloc[:df.index.get_loc('2019-12-31')+1,:] - z_lag\n",
    "\n",
    "halflife=[]\n",
    "\n",
    "for i in range(0,len(spread_norm.columns)):\n",
    "    z_lag2 = sm.add_constant(z_lag[z_lag.columns[i]])\n",
    "    model = sm.OLS(z_ret[z_lag.columns[i]],z_lag2, missing='drop')\n",
    "    res = model.fit()\n",
    "    halflife.append(-np.log(2) / res.params[1])\n",
    "halflife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hurst exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boillinger\n",
    "boilstart='2020-01-02'\n",
    "\n",
    "betaboil=pd.DataFrame(index=df.index, columns=spreaddf.columns)\n",
    "spreaddfboil=pd.DataFrame(index=df.index)\n",
    "zdfboil=pd.DataFrame(index=df.index, columns=spreaddf.columns)\n",
    "\n",
    "for i in range(0,len(pairs)):\n",
    "    S1=df.loc[:,pairs[i].split(' ')[0]].to_numpy()\n",
    "    S1= sm.add_constant(df.loc[:,pairs[i].split(' ')[0]]).to_numpy()\n",
    "    S2=(df.loc[:,pairs[i].split(' ')[1]].to_numpy())\n",
    "    S2=S2.reshape(len(S2),1)\n",
    "            \n",
    "    S1_partial=df.loc[:boilstart,pairs[i].split(' ')[0]].to_numpy()\n",
    "    S1_partial = sm.add_constant(df.loc[:boilstart,pairs[i].split(' ')[0]]).to_numpy()\n",
    "    S2_partial=df.loc[:boilstart,pairs[i].split(' ')[1]].to_numpy()\n",
    "    S2_partial=S2_partial.reshape(len(S2_partial),1)\n",
    "    results = sm.OLS(S2_partial, S1_partial).fit()\n",
    "    spread = df.loc[:,pairs[i].split(' ')[1]] - (np.dot(S1,results.params))\n",
    "    spreaddfboil[pairs[i].split(' ')[0] + \" \"+ pairs[i].split(' ')[1]] = spread \n",
    "    betaboil.iloc[:,i]=(results.params[1])\n",
    "        \n",
    "    for j in range(df.index.get_loc(boilstart), len(df)):\n",
    "        results = sm.OLS(S2[0:(j+1)], S1[0:(j+1)]).fit()\n",
    "        spread = S2[:(j+1)]-(np.dot(S1[:(j+1)],results.params)).reshape(j+1,1)\n",
    "        spreaddfboil.iloc[j,i] = spread[-1]\n",
    "        betaboil.iloc[j,i]=(results.params[1])\n",
    "        \n",
    "#MA_ series\n",
    "lengthwindow=100\n",
    "mavg_30 = spreaddfboil.rolling(window=lengthwindow, center=False).mean()  \n",
    "mavg_30.iloc[:lengthwindow,:]=np.array(mavg_30.iloc[lengthwindow,:].to_list()*lengthwindow).reshape(lengthwindow,len(pairs))\n",
    "mstd_30 = spreaddfboil.rolling(window=lengthwindow, center=False).std()\n",
    "mstd_30.iloc[:lengthwindow,:]=np.array(mstd_30.iloc[lengthwindow,:].to_list()*lengthwindow).reshape(lengthwindow,len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=[]\n",
    "for i in range(0,len(spreaddf.columns)):\n",
    "    names.append(spreaddf.columns[i].split()[0])\n",
    "    names.append(spreaddf.columns[i].split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make plot to illustrate point about Reduction of pairs\n",
    "dato=[]\n",
    "dato= pd.to_datetime(df.index, format='%Y-%m-%d')\n",
    "\n",
    "upper=10\n",
    "lower=-10\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches(14, 5)\n",
    "axs[0].plot(dato, oldpairsspread.loc[:,:] ,color='grey', linewidth=0.6)\n",
    "axs[0].set_ylim(lower,upper)\n",
    "axs[0].set_title('(a)', y=-0.10)\n",
    "axs[0].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.15)\n",
    "\n",
    "axs[1].plot(dato, spread_norm.loc[:,:],color='grey',linewidth=0.6)\n",
    "axs[1].set_ylim(lower,upper)\n",
    "axs[1].set_title('(b)', y=-0.10)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "axs[1].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.15)\n",
    "\n",
    "plt.setp(axs[0], ylabel='Standardized spread ($z_t$)')\n",
    "\n",
    "\n",
    "fig.savefig('XXX.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implemination of Pairs Trading Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hvilke univers undersÃ¸ges\n",
    "#Beta names= beta_norm,betaroll,betaboil\n",
    "#Spread names= spread_norm,spreaddfroll,spreaddfboil\n",
    "beta=betaroll.iloc[:df.index.get_loc('2019-12-31')+1,:]\n",
    "investigated=spreaddfroll.iloc[:df.index.get_loc('2019-12-31')+1,:] #df.index.get_loc('2019-12-31')+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heinopair(data,tresh, stoploss,is_bband,mavg__30,mstd__30,stdgap,stpls):\n",
    "    tradecost=0.003 # 0.001 + 0.002\n",
    "    tradelog= pd.DataFrame(0, index=data.index, columns=data.columns)\n",
    "    pairreturn=pd.DataFrame(math.nan, index=data.index, columns=data.columns)\n",
    "    tradeinf = dict.fromkeys(data.columns)\n",
    "    closeslice=pd.DataFrame(0, index=data.index, columns=data.columns)\n",
    "    closeslice=close.iloc[close.index.get_loc(data.index[0]):close.index.get_loc(data.index[-1])+1,:]\n",
    "    \n",
    "    #additional parameters with Bollinger band\n",
    "    if bool(is_bband) == True:\n",
    "        #stdgap=2\n",
    "        #stpls=5\n",
    "        diffspreadMA =data-mavg__30.iloc[mavg__30.index.get_loc(data.index[0]):,:]\n",
    "    \n",
    "    for i in range(0,data.shape[1]):\n",
    "        S1=data.columns[i].split(' ')[0]\n",
    "        S2=data.columns[i].split(' ')[1]\n",
    "        stopped_out=0\n",
    "        for j in range(0,len(data)):\n",
    "            status=0\n",
    "            \n",
    "            #Bollinger Bands\n",
    "            if bool(is_bband) == True:\n",
    "                if data.iloc[j,i]>=mavg__30.iloc[j+mavg__30.index.get_loc(data.index[0]),i]+stpls*mstd__30.iloc[j+mavg__30.index.get_loc(data.index[0]),i] or data.iloc[j,i]<=mavg__30.iloc[j+mavg__30.index.get_loc(data.index[0]),i]-stpls*mstd__30.iloc[j+mavg__30.index.get_loc(data.index[0]),i]:\n",
    "                    stopped_out=1\n",
    "                elif stopped_out==1 and np.sign(diffspreadMA.iloc[j,i])!=np.sign(diffspreadMA.iloc[j-1,i]):\n",
    "                    stopped_out=0\n",
    "                    \n",
    "                #Faktisk strategi\n",
    "                if stopped_out==0 and data.iloc[j,i]>=mavg__30.iloc[j+mavg__30.index.get_loc(data.index[0]),i]+stdgap*mstd__30.iloc[j+mavg__30.index.get_loc(data.index[0]),i] or stopped_out==0 and (j>=1 and tradelog.iloc[j-1,i]==1 and data.iloc[j,i]>mavg__30.iloc[j+mavg__30.index.get_loc(data.index[0]),i]):\n",
    "                    status=1 #betyder short S2, lang S1\n",
    "                    tradelog.iloc[j,i]=status\n",
    "                elif stopped_out==0 and data.iloc[j,i]<=mavg__30.iloc[j+mavg__30.index.get_loc(data.index[0]),i]-stdgap*mstd__30.iloc[j+mavg__30.index.get_loc(data.index[0]),i] or stopped_out==0 and(j>=1 and tradelog.iloc[j-1,i]==-1 and data.iloc[j,i]<mavg__30.iloc[j+mavg__30.index.get_loc(data.index[0]),i]):\n",
    "                    status=-1 #betyder short S1, lang S2\n",
    "                    tradelog.iloc[j,i]=status\n",
    "            \n",
    "            #Not Bollinger Bands but instead the \"standard implementation\"\n",
    "            elif bool(is_bband) == False:\n",
    "                #Stoploss strat\n",
    "                if abs(data.iloc[j,i])>=stoploss:\n",
    "                    stopped_out=1\n",
    "                elif stopped_out==1 and abs(data.iloc[j,i]+data.iloc[j-1,i])!=abs(data.iloc[j,i])+abs(data.iloc[j-1,i]):\n",
    "                    stopped_out=0\n",
    "                #Faktisk strategi\n",
    "                if stopped_out==0 and data.iloc[j,i]>=tresh or stopped_out==0 and (j>=1 and tradelog.iloc[j-1,i]==1 and data.iloc[j,i]>0):\n",
    "                    status=1 #betyder short S2, lang S1\n",
    "                    tradelog.iloc[j,i]=status\n",
    "                elif stopped_out==0 and data.iloc[j,i]<=-tresh or stopped_out==0 and(j>=1 and tradelog.iloc[j-1,i]==-1 and data.iloc[j,i]<0):\n",
    "                    status=-1 #betyder short S1, lang S2\n",
    "                    tradelog.iloc[j,i]=status\n",
    "            \n",
    "            \n",
    "            #Praktisk implementering herfra\n",
    "            if tradelog.iloc[j-1,i]-tradelog.iloc[j,i]!=0 and status!=0:\n",
    "                info=[]\n",
    "                \n",
    "                tradestart=j\n",
    "                amt_S2= (math.floor(100000/closeslice.iloc[j,closeslice.columns.get_loc(S2)]))\n",
    "                amt_S1= ((math.floor(beta.iloc[j,i]*closeslice.iloc[j,closeslice.columns.get_loc(S2)]*amt_S2/closeslice.iloc[j,closeslice.columns.get_loc(S1)])))\n",
    "                limit=closeslice.iloc[j,closeslice.columns.get_loc(S1)]*amt_S1\n",
    "                if limit>100000:\n",
    "                    amt_S1= (math.floor(100000/closeslice.iloc[j,closeslice.columns.get_loc(S1)]))\n",
    "                    amt_S2= ((math.floor(closeslice.iloc[j,closeslice.columns.get_loc(S1)]*amt_S1/(closeslice.iloc[j,closeslice.columns.get_loc(S2)]*beta.iloc[j,i]))))\n",
    "                \n",
    "                xtramny=closeslice.iloc[j,closeslice.columns.get_loc(S2)]*amt_S2+closeslice.iloc[j,closeslice.columns.get_loc(S1)]*amt_S1\n",
    "                \n",
    "                startval=amt_S2*closeslice.iloc[j,closeslice.columns.get_loc(S2)]+amt_S1*closeslice.iloc[j,closeslice.columns.get_loc(S1)]\n",
    "                \n",
    "                info.append(round(startval,2))\n",
    "                info.append(round(xtramny,2))\n",
    "                info.append(round(amt_S1*closeslice.iloc[j,closeslice.columns.get_loc(S1)],2))\n",
    "                info.append(round(amt_S2*closeslice.iloc[j,closeslice.columns.get_loc(S2)],2))\n",
    "                info.append(tradestart)\n",
    "                \n",
    "            elif tradelog.iloc[j,i]!=0:\n",
    "                caldays = datetime.fromisoformat(closeslice.index.to_series()[j])-datetime.fromisoformat(closeslice.index.to_series()[tradestart])\n",
    "                shortcost=(-status-1)/(-2)*amt_S2*closeslice.iloc[tradestart,closeslice.columns.get_loc(S2)]*((short_cost[S2][0])**(caldays.days)-1)+(status-1)/(-2)*amt_S1*closeslice.iloc[tradestart,closeslice.columns.get_loc(S1)]*((short_cost[S1][0])**(caldays.days)-1)\n",
    "                pairreturn.iloc[j,i]=((tradelog.iloc[j-1,i]*((closeslice.iloc[j,closeslice.columns.get_loc(S1)]-closeslice.iloc[tradestart,closeslice.columns.get_loc(S1)])*amt_S1-(closeslice.iloc[j,closeslice.columns.get_loc(S2)]-closeslice.iloc[tradestart,closeslice.columns.get_loc(S2)])*amt_S2)*(1-tradecost)-tradecost*startval-shortcost)/startval)\n",
    "                \n",
    "                if (j==len(data)-1):\n",
    "                    info.append(j)\n",
    "                    if not (tradeinf[spreaddf.columns[i]]):\n",
    "                        tradeinf[spreaddf.columns[i]]=[info]\n",
    "                    else:\n",
    "                        tradeinf[spreaddf.columns[i]].append(info)\n",
    "\n",
    "            elif tradelog.iloc[j-1,i]-tradelog.iloc[j,i]!=0 and status==0:\n",
    "                caldays = datetime.fromisoformat(closeslice.index.to_series()[j])-datetime.fromisoformat(closeslice.index.to_series()[tradestart])\n",
    "                shortcost=(-status-1)/(-2)*amt_S2*closeslice.iloc[tradestart,closeslice.columns.get_loc(S2)]*((short_cost[S2][0])**(caldays.days)-1)+(status-1)/(-2)*amt_S1*closeslice.iloc[tradestart,closeslice.columns.get_loc(S1)]*((short_cost[S1][0])**(caldays.days)-1)\n",
    "                pairreturn.iloc[j,i]=((tradelog.iloc[j-1,i]*((closeslice.iloc[j,closeslice.columns.get_loc(S1)]-closeslice.iloc[tradestart,closeslice.columns.get_loc(S1)])*amt_S1-(closeslice.iloc[j,closeslice.columns.get_loc(S2)]-closeslice.iloc[tradestart,closeslice.columns.get_loc(S2)])*amt_S2)*(1-tradecost)-tradecost*startval-shortcost)/startval)\n",
    "                \n",
    "                info.append(j)\n",
    "                if not (tradeinf[spreaddf.columns[i]]):\n",
    "                    tradeinf[spreaddf.columns[i]]=[info]\n",
    "                else:\n",
    "                    tradeinf[spreaddf.columns[i]].append(info)\n",
    "                    \n",
    "    return tradelog, pairreturn, tradeinf\n",
    "\n",
    "\n",
    "#Tradeinfo holds a list for each trade with (1:total invested (short+long amt),2: money \"Excess\"\n",
    "#,3: invested in S1 ,4: invested in S2 ,5:day opened, 6: day closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heinotrade,retdf, tradeinf =heinopair(investigated,2,5,False,mavg_30,mstd_30,1.5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#________________OPtimizer function______________________ \n",
    "def tradegain(tresh, stopl, data,stdgap,stpls):\n",
    "    \n",
    "    _,retdf, tradeinf=heinopair(data,tresh, stopl,False,mavg_30,mstd_30,stdgap,stpls)\n",
    "    \n",
    "    yo=[]\n",
    "    k=0\n",
    "    for i in range(0,len(data.keys())):\n",
    "        if not tradeinf[data.columns[i]]:\n",
    "            k=1+k\n",
    "\n",
    "        else:\n",
    "            for j in range(0,len(tradeinf[data.columns[i]])):\n",
    "                yo.append(retdf.iloc[tradeinf[data.columns[i]][j][5],i]*tradeinf[data.columns[i]][j][0])\n",
    "\n",
    "    return sum(yo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongain=tradegain(2,5,investigated,1.5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max360=np.unravel_index(np.argmax(z360), z360.shape)\n",
    "#print(x180[max180[0]][max180[1]],y180[max180[0]][max180[1]],z180[max180[0]][max180[1]])\n",
    "print(x360[max360[0]][max360[1]],y360[max360[0]][max360[1]],z360[max360[0]][max360[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_measaure=pd.DataFrame(rr_measaure)\n",
    "rr_measaures=rr_measaure.groupby([0]).sum()\n",
    "rr_measaurem=rr_measaure.groupby([0]).mean()\n",
    "rr_measauref=pd.DataFrame([rr_measaurem[1],rr_measaures[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_measauref.iloc[0,:]=rr_measauref.iloc[0,:].div(rr_measauref.iloc[0,:].sum())\n",
    "weighted_stats = DescrStatsW(rr_measauref.iloc[1,:], weights=rr_measauref.iloc[0,:], ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weighted_stats.mean/weighted_stats.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate returns for pairs and the port\n",
    "rr_measaure=[]\n",
    "dato=[]\n",
    "dato= pd.to_datetime(investigated.index, format='%Y-%m-%d')\n",
    "totalret=[]\n",
    "avgday=[]\n",
    "avgsize=[]\n",
    "pr=0\n",
    "for i in range(0,len(tradeinf.keys())):\n",
    "        t=0\n",
    "        n=0\n",
    "        length=0\n",
    "        size=0\n",
    "        if not tradeinf[investigated.columns[i]]:\n",
    "            avgsize.append(0)\n",
    "            avgday.append(0)\n",
    "            totalret.append(0)\n",
    "        else:\n",
    "            for j in range(0,len(tradeinf[spreaddf.columns[i]])):\n",
    "                n=n+tradeinf[spreaddf.columns[i]][j][0]\n",
    "                t=t+tradeinf[spreaddf.columns[i]][j][0]*(retdf.iloc[tradeinf[spreaddf.columns[i]][j][5],i]+1)\n",
    "                length=length+tradeinf[spreaddf.columns[i]][j][5]-tradeinf[spreaddf.columns[i]][j][4]\n",
    "                size=size+tradeinf[spreaddf.columns[i]][j][0]\n",
    "                rr_measaure.append([i,tradeinf[spreaddf.columns[i]][j][0],retdf.iloc[tradeinf[spreaddf.columns[i]][j][5],i]*100])\n",
    "            avgsize.append(size/len(tradeinf[spreaddf.columns[i]]))\n",
    "            avgday.append(length/len(tradeinf[spreaddf.columns[i]]))\n",
    "            totalret.append((t/n-1)*len(tradeinf[spreaddf.columns[i]]))\n",
    "            pr=pr+(t-n)/mongain*(t/n-1)*len(tradeinf[spreaddf.columns[i]])\n",
    "            \n",
    "totalret.append(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabel in sample data\n",
    "handler=[]\n",
    "for i in range(0,len(tradeinf.keys())):\n",
    "    if not tradeinf[spreaddf.columns[i]]:\n",
    "        handler.append(0)\n",
    "    else:\n",
    "        handler.append(len(tradeinf[spreaddf.columns[i]]))\n",
    "    \n",
    "oversigtstabel=pd.DataFrame(handler, index=spreaddf.columns,columns=['No. of trades'])\n",
    "oversigtstabel=oversigtstabel.append(pd.Series(name='Total'))\n",
    "oversigtstabel.iloc[-1,0]=oversigtstabel.iloc[:-1,0].sum(axis=0)\n",
    "avgday.append(sum(oversigtstabel.iloc[:-1,0]*avgday/oversigtstabel.iloc[-1,0]))\n",
    "oversigtstabel['Avg. days position open']=avgday #Alternativ\n",
    "oversigtstabel['Fraction of period open']=oversigtstabel['No. of trades']*oversigtstabel['Avg. days position open']/len(investigated)\n",
    "oversigtstabel['Fraction of period open'][-1]=1\n",
    "avgsize.append(sum(oversigtstabel.iloc[:-1,0]*avgsize/oversigtstabel.iloc[-1,0]))\n",
    "oversigtstabel['Avg. trade size']=avgsize\n",
    "oversigtstabel['Return']=np.round(np.multiply(totalret,100),2)\n",
    "oversigtstabel['Return'][-1]=((oversigtstabel['Avg. trade size'][:-1]/oversigtstabel['Avg. trade size'][:-1].sum())*oversigtstabel['Return'][:-1]).sum()\n",
    "oversigtstabel['Ann. return']=oversigtstabel['Return'].apply(lambda x: ((1+x/100)**(1/round((dato[-1]-dato[0]).days/365))-1)*100)\n",
    "oversigtstabel['Return (USD)']=oversigtstabel['Avg. trade size']*oversigtstabel['Return']/100\n",
    "oversigtstabel['Return (USD)'][-1]=mongain\n",
    "\n",
    "for i in oversigtstabel.columns:\n",
    "    oversigtstabel[i]=oversigtstabel[i].apply(lambda x: round(x,2))\n",
    "    \n",
    "oversigtstabel\n",
    "#Avg return pr trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _________________Graph dev section below___________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "plt.rc('axes', prop_cycle=(cycler('color', ['tab:red', '#08519c', 'black']) +\n",
    "                           cycler('linestyle', ['-','-','-'])))\n",
    "\n",
    "dato=[]\n",
    "dato= pd.to_datetime(investigated.index, format='%Y-%m-%d')\n",
    "\n",
    "def abline(slope, intercept,j,k):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    x_vals = np.array(axs[j,k].get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    axs[j,k].plot(x_vals, y_vals, color='tab:red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Res = sm.OLS(dailylist,list(pd.concat([bm_daily.loc[daily_ret.index,bm_daily.columns[2*j+k]]]*len(pairs))),missing='drop').fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm=pd.read_csv(\"Benchm.csv\", index_col=0)\n",
    "bm.iloc[:,-1]=(((bm.iloc[:,-1]/100+1)**(1/252)-1)*100) #RF rate\n",
    "bm.iloc[:,-1].fillna(method='ffill')\n",
    "bm=bm.loc[retdf.index,bm.columns]\n",
    "#makes a list of daily returns stacking each pair\n",
    "daily_ret=((retdf+1)/(retdf+1).shift()-1)*100\n",
    "daily_ret=daily_ret.subtract(bm.iloc[:,-1],axis=0)\n",
    "bm_daily=(bm/bm.shift()-1)*100\n",
    "bm_daily=bm_daily.subtract(bm.iloc[:,-1],axis=0)\n",
    "\n",
    "dailylist=[]\n",
    "for i in range(0,daily_ret.shape[1]):\n",
    "    dailylist.append(daily_ret.iloc[:,i].values.tolist())\n",
    "dailylist = [item for sublist in dailylist for item in sublist]\n",
    "\n",
    "#heatmap, xedges, yedges = np.histogram2d(good_x,good_y, bins=[120,250])\n",
    "#extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_size_inches(15,10)\n",
    "bogstaver=['(a)','(b)','(c)','(d)']\n",
    "\n",
    "for j in range(0,2):\n",
    "    for k in range(0,2):\n",
    "        for i in range(0,len(pairs)):\n",
    "#             bad_indices = np.isnan(len(pd.concat([bm_daily.loc[daily_ret.index,bm_daily.columns[2*j+k]]]*len(pairs)))) | np.isnan(dailylist)\n",
    "#             good_indices = ~bad_indices\n",
    "#             good_x = pd.concat([bm_daily.loc[daily_ret.index,bm_daily.columns[2*j+k]]]*len(pairs))[good_indices]\n",
    "#             good_y = list(compress(dailylist,good_indices))\n",
    "\n",
    "            Res = sm.OLS(dailylist,sm.add_constant(list(pd.concat([bm_daily.loc[daily_ret.index,bm_daily.columns[2*j+k]]]*len(pairs)))),missing='drop').fit(cov_type='HC0') \n",
    "            axs[j,k].scatter(bm_daily.loc[daily_ret.index,bm_daily.columns[2*j+k]],daily_ret.iloc[:,i],s=0.5,alpha=0.6, color='dimgray')\n",
    "            axs[j,k].axvline(x=0,color='black', linewidth=0.6)\n",
    "            axs[j,k].hlines(0,-5, 5,color='black',linewidth=0.6)\n",
    "#             slope, intercept = np.polyfit(good_x, good_y, 1)\n",
    "            abline(Res.params[1],Res.params[0],j,k)\n",
    "            textstr = '\\n'.join((r'$\\alpha=\\underset{[%.3f]}{%.2f}$' % (Res.bse[0],Res.params[0]),r'$\\beta=\\underset{[%.3f]}{%.3f}$' % (Res.bse[1],Res.params[1])))\n",
    "            axs[j,k].text(2.5, 3.5, textstr, fontsize=10, verticalalignment='top',bbox=dict(facecolor='none', edgecolor='black', pad=5, linewidth=0.4),linespacing = 1.5)\n",
    "            axs[j,k].set_ylim(-4,4)\n",
    "            axs[j,k].set_xlim(-4,4)\n",
    "            axs[j,k].set_title(bogstaver[2*j+k], y=-0.12)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "fig.savefig('corr_full.pdf', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sm.OLS(bm_daily.iloc[:,0],bm_daily.iloc[:,2], missing='drop').fit(cov_type='HC0')\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sm.OLS(bm_daily.iloc[:len(daily_ret),0],bm_daily.iloc[:len(daily_ret),1], missing='drop').fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "for i in range(0,len(pairs)):\n",
    "    retdf.iloc[:,i].plot.line(figsize=(10,5),legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper=4\n",
    "lower=-4\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "axs[0, 0].plot(dato, heinotrade.iloc[:,6],color='black',linewidth=1.2)\n",
    "axs[0, 0].plot(dato, investigated.iloc[:,6],color='tab:red',linewidth=0.8)\n",
    "axs[0, 0].plot(dato, retdf.iloc[:,6]*10,color='green',linewidth=0.8)\n",
    "axs[0, 0].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[0, 0].set_ylim(lower,upper)\n",
    "#axs[0, 0].title.set_text(\"(a)\",y=1.25)\n",
    "axs[0, 0].set_title(pairs[6], y=1)\n",
    "axs[0, 1].plot(dato, heinotrade.iloc[:,-1],color='black',linewidth=1.2)\n",
    "axs[0, 1].plot(dato, investigated.iloc[:,-1],color='tab:red',linewidth=0.8)\n",
    "axs[0, 1].plot(dato, retdf.iloc[:,-1]*10,color='green',linewidth=0.8)\n",
    "axs[0, 1].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[0, 1].set_ylim(lower,upper)\n",
    "axs[0, 1].set_title(pairs[-1], y=1)\n",
    "axs[1, 0].plot(dato, heinotrade.iloc[:,-3],color='black',linewidth=1.2)\n",
    "axs[1, 0].plot(dato, investigated.iloc[:,-3],color='tab:red',linewidth=0.8)\n",
    "axs[1, 0].plot(dato, retdf.iloc[:,-3]*10,color='green',linewidth=0.8)\n",
    "axs[1, 0].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[1, 0].set_ylim(lower,upper)\n",
    "axs[1, 0].set_title(pairs[-3], y=1)\n",
    "axs[1, 1].plot(dato, heinotrade.iloc[:,-2],color='black',linewidth=1.2)\n",
    "axs[1, 1].plot(dato, investigated.iloc[:,-2],color='tab:red',linewidth=0.8)\n",
    "axs[1, 1].plot(dato, retdf.iloc[:,-2]*10,color='green',linewidth=0.8)\n",
    "axs[1, 1].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[1, 1].set_ylim(lower,upper)\n",
    "#axs[1, 1].title.set_text(\"(d)\")\n",
    "axs[1, 1].set_title(pairs[-2], y=1)\n",
    "plt.subplots_adjust(wspace=0.10, hspace=0.25)\n",
    "\n",
    "fig.savefig('BTradeoverview.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#    print(heinotrade.loc[:,pairs[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parnr=6\n",
    "lul=retdf.iloc[df.index.get_loc('2018-07-10'):df.index.get_loc('2018-12-20'),parnr]*10\n",
    "heinotrade.iloc[df.index.get_loc('2018-07-10'):df.index.get_loc('2018-12-20'),parnr].plot.line(figsize=(10,5),legend=False,color='black',linewidth=1.2)\n",
    "investigated.iloc[df.index.get_loc('2018-07-10'):df.index.get_loc('2018-12-20'),parnr].plot.line(figsize=(10,5),legend=False,color='tab:red',linewidth=0.8)\n",
    "lul.plot.line(figsize=(10,5),legend=False,color='green',linewidth=0.8)\n",
    "plt.savefig('Fredetrade.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bollinger Bands graph\n",
    "boilnr=2\n",
    "mavg_30.iloc[:,boilnr].plot.line()\n",
    "spreaddfboil.iloc[:,boilnr].plot.line()\n",
    "lul1=mavg_30.iloc[:,boilnr]+2*mstd_30.iloc[:,boilnr]\n",
    "lul2=mavg_30.iloc[:,boilnr]-2*mstd_30.iloc[:,boilnr]\n",
    "lul1.plot.line()\n",
    "lul2.plot.line(figsize=(10,5), color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boil\n",
    "upper=2\n",
    "lower=-2\n",
    "rightl=-0.5\n",
    "rightu=0.5\n",
    "\n",
    "fig, axs = plt.subplots(4, 2)\n",
    "\n",
    "\n",
    "#fig.set_size_inches(10, 5)\n",
    "axs[0, 0].plot(dato, heinotrade.iloc[:,6],color='black',linewidth=1.2)\n",
    "axs[0, 0].plot(dato, investigated.iloc[:,6],color='tab:red',linewidth=0.8)\n",
    "axs[0, 0].plot(dato, retdf.iloc[:,6]*10,color='green',linewidth=0.8)\n",
    "axs[0, 0].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[0, 0].set_ylim(lower,upper)\n",
    "#band\n",
    "axs[0, 1].plot(dato, mavg_30.iloc[:,6],color='#08519c')\n",
    "axs[0, 1].plot(dato, spreaddfboil.iloc[:,6],color='tab:red',linewidth=0.8)\n",
    "axs[0, 1].plot(dato, mavg_30.iloc[:,6]+1.5*mstd_30.iloc[:,6],color='black',linestyle='--',linewidth=0.8)\n",
    "axs[0, 1].plot(dato, mavg_30.iloc[:,6]-1.5*mstd_30.iloc[:,6],color='black',linestyle='--',linewidth=0.8)\n",
    "axs[0, 1].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[0, 1].set_ylim(rightl,rightu)\n",
    "axs[0,1].legend(['Spread 360d MA','Spread', 'Entry bands'], fontsize=8) #\n",
    "\n",
    "axs[1, 0].plot(dato, heinotrade.iloc[:,-1],color='black',linewidth=1.2)\n",
    "axs[1, 0].plot(dato, investigated.iloc[:,-1],color='tab:red',linewidth=0.8)\n",
    "axs[1, 0].plot(dato, retdf.iloc[:,-1]*10,color='green',linewidth=0.8)\n",
    "axs[1, 0].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[1, 0].set_ylim(lower,upper)\n",
    "axs[1, 1].plot(dato, mavg_30.iloc[:,-1],color='#08519c')\n",
    "axs[1, 1].plot(dato, spreaddfboil.iloc[:,-1],color='tab:red',linewidth=0.8)\n",
    "axs[1, 1].plot(dato, mavg_30.iloc[:,-1]+1.5*mstd_30.iloc[:,-1],color='black',linestyle='--',linewidth=0.8)\n",
    "axs[1, 1].plot(dato, mavg_30.iloc[:,-1]-1.5*mstd_30.iloc[:,-1],color='black',linestyle='--',linewidth=0.8)\n",
    "axs[1, 1].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[1, 1].set_ylim(rightl,rightu)\n",
    "axs[1,1].legend(['Spread 360d MA','Spread', 'Entry bands'], fontsize=8) #\n",
    "\n",
    "axs[2, 0].plot(dato, heinotrade.iloc[:,-3],color='black',linewidth=1.2)\n",
    "axs[2, 0].plot(dato, investigated.iloc[:,-3],color='tab:red',linewidth=0.8)\n",
    "axs[2, 0].plot(dato, retdf.iloc[:,-3]*10,color='green',linewidth=0.8)\n",
    "axs[2, 0].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[2, 0].set_ylim(lower,upper)\n",
    "axs[2, 1].plot(dato, mavg_30.iloc[:,-3],color='#08519c')\n",
    "axs[2, 1].plot(dato, spreaddfboil.iloc[:,-3],color='tab:red',linewidth=0.8)\n",
    "axs[2, 1].plot(dato, mavg_30.iloc[:,-3]+1.5*mstd_30.iloc[:,-3],color='black',linestyle='--',linewidth=0.8)\n",
    "axs[2, 1].plot(dato, mavg_30.iloc[:,-3]-1.5*mstd_30.iloc[:,-3],color='black',linestyle='--',linewidth=0.8)\n",
    "axs[2, 1].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[2, 1].set_ylim(rightl,rightu)\n",
    "axs[2,1].legend(['Spread 360d MA','Spread', 'Entry bands'], fontsize=8) #\n",
    "\n",
    "\n",
    "axs[3, 0].plot(dato, heinotrade.iloc[:,-2],color='black',linewidth=1.2)\n",
    "axs[3, 0].plot(dato, investigated.iloc[:,-2],color='tab:red',linewidth=0.8)\n",
    "axs[3, 0].plot(dato, retdf.iloc[:,-2]*10,color='green',linewidth=0.8)\n",
    "axs[3, 0].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[3, 0].set_ylim(lower,upper)\n",
    "axs[3, 1].plot(dato, mavg_30.iloc[:,-2],color='#08519c')\n",
    "axs[3, 1].plot(dato, spreaddfboil.iloc[:,-2],color='tab:red',linewidth=0.8)\n",
    "axs[3, 1].plot(dato, mavg_30.iloc[:,-2]+1.5*mstd_30.iloc[:,-2],color='black',linestyle='--',linewidth=0.8)\n",
    "axs[3, 1].plot(dato, mavg_30.iloc[:,-2]-1.5*mstd_30.iloc[:,-2],color='black',linestyle='--',linewidth=0.8)\n",
    "axs[3, 1].axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1)\n",
    "axs[3, 1].set_ylim(rightl,rightu)\n",
    "axs[3, 1].legend(['Spread 360d MA','Spread', 'Entry bands'], fontsize=8) #\n",
    "\n",
    "#axs[1, 1].title.set_text(\"(d)\")\n",
    "plt.subplots_adjust(wspace=0.10, hspace=0.35)\n",
    "\n",
    "axs[0,0].text('2020-11-02', 2.5, pairs[6], fontsize=14, verticalalignment='top',bbox=dict(facecolor='none', edgecolor='black', pad=5, linewidth=0),linespacing = 1.5)\n",
    "axs[1,0].text('2020-11-02', 2.5, pairs[-1], fontsize=14, verticalalignment='top',bbox=dict(facecolor='none', edgecolor='black', pad=5, linewidth=0),linespacing = 1.5)\n",
    "axs[2,0].text('2020-11-02', 2.5, pairs[-3], fontsize=14, verticalalignment='top',bbox=dict(facecolor='none', edgecolor='black', pad=5, linewidth=0),linespacing = 1.5)\n",
    "axs[3,0].text('2020-11-02', 2.5, pairs[-2], fontsize=14, verticalalignment='top',bbox=dict(facecolor='none', edgecolor='black', pad=5, linewidth=0),linespacing = 1.5)\n",
    "\n",
    "fig.savefig('Boil_Tradeoverview.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 2)\n",
    "k=0\n",
    "for i in range(0,6):\n",
    "    for j in range(0,2):\n",
    "        axs[i,j].yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "        axs[i,j].locator_params(axis='y', nbins=4)\n",
    "        axs[i,j].plot(dato, close.loc[:,pairs[k].split(' ')[0]],linewidth=0.8)\n",
    "        lul=(close.loc[:,pairs[k].split(' ')[1]]-close.loc[:,pairs[k].split(' ')[1]].mean())/(close.loc[:,pairs[k].split(' ')[1]].std())*close.loc[:,pairs[k].split(' ')[0]].std()+close.loc[:,pairs[k].split(' ')[0]].mean()\n",
    "        axs[i,j].plot(dato, lul,linewidth=0.8)\n",
    "        axs[i,j].legend(pairs[k].split(' '),loc=2,fontsize=8)\n",
    "        k=1+k\n",
    "        \n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "fig.savefig('Prices_matchbymeanandstd.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import MaxNLocator\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "                         \n",
    "fig, axs = plt.subplots(6, 2)\n",
    "k=0\n",
    "for i in range(0,6):\n",
    "    for j in range(0,2):\n",
    "        axs[i,j].yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "        axs[i,j].locator_params(axis='y', nbins=4)\n",
    "        axs[i,j].plot(dato, close.loc[:,pairs[k].split(' ')],linewidth=0.8)\n",
    "        axs[i,j].legend(pairs[k].split(' '),loc=2,fontsize=8)\n",
    "        k=1+k\n",
    "        \n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "\n",
    "\n",
    "\n",
    "fig.savefig('Allpairsprice.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "for i in range(0,2):\n",
    "    for j in range(0,2):\n",
    "        axs[i,j].yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "axs[0, 0].plot(dato, close.loc[:'2019-12-31',['PVG', 'KGC']],linewidth=0.8)\n",
    "axs[0, 0].set_title('(a)', y=-0.20)\n",
    "axs[0, 1].plot(dato, close.loc[:'2019-12-31',['HMY', 'AG']],linewidth=0.8)\n",
    "axs[0, 1].set_title('(b)', y=-0.20)\n",
    "#axs[0, 1].set_ylim(0,6.5)\n",
    "axs[1, 0].plot(dato, close.loc[:'2019-12-31',['GFI', 'IAU']],linewidth=0.8)\n",
    "axs[1, 0].set_title('(c)', y=-0.20)\n",
    "axs[1, 1].plot(dato, close.loc[:'2019-12-31',['KGC', 'GOLD']],linewidth=0.8)\n",
    "axs[1, 1].set_title('(d)', y=-0.20)\n",
    "#axs[1, 1].set_ylim(0.5,4)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "axs[0, 0].legend(['PVG', 'KGC'],loc=2,fontsize=8)\n",
    "axs[0, 1].legend(['HMY', 'AG'],loc=2,fontsize=8)\n",
    "axs[1, 0].legend(['GFI', 'IAU'],loc=2,fontsize=8)\n",
    "axs[1, 1].legend(['KGC', 'GOLD'],loc=2,fontsize=8)\n",
    "\n",
    "\n",
    "\n",
    "fig.savefig('Fullprices.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regne eksempel for at overbevise om ekstreme afkast\n",
    "tradeinf['BTG NEM']\n",
    "df.loc[:,['BTG','NEM']]\n",
    "S1_partial = sm.add_constant(df.loc[firstobs:'2020-01-02','BTG']).to_numpy()\n",
    "S2_partial=df.loc[firstobs:'2020-01-02','NEM'].to_numpy()\n",
    "S2_partial=S2_partial.reshape(len(S2_partial),1)\n",
    "results = sm.OLS(S2_partial, S1_partial).fit()\n",
    "results.params\n",
    "#return\n",
    "((close['BTG'][457]-close['BTG'][266])*beta[12]*100/close['BTG'][266]-(close['NEM'][457]-close['NEM'][266])*100/close['NEM'][266])/(close['BTG'][266]*beta[12]*100/close['BTG'][266]+close['NEM'][266]*100/close['NEM'][266])\n",
    "#penge tjent pÃ¥ position\n",
    "((close['BTG'][457]-close['BTG'][266])*beta[12]*100/close['BTG'][266]-(close['NEM'][457]-close['NEM'][266])*100/close['NEM'][266])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread1 = df.loc[:'2020-01-02','NEM'] - np.dot(S1_partial,results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread1=spread1/spread1.std()\n",
    "(df['NEM'][266]-(df['BTG'][266]*results.params[1]+results.params[0]))/spread1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(close['BTG'][457]-close['BTG'][266])*beta[12]*100/close['BTG'][266]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(close['BTG'][457],close['BTG'][266])\n",
    "print(close['NEM'][457],close['NEM'][266])\n",
    "\n",
    "print(close['BTG'][457],close['BTG'][266],beta[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return\n",
    "((close['BTG'][457]-close['BTG'][266])*beta[12]*100/close['BTG'][266]-(close['NEM'][457]-close['NEM'][266])*100/close['NEM'][266])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['BTG','NEM']].plot.line(figsize=(10,5),legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 12\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.jet(np.linspace(0,1,N))[:,0:3]*0.75)\n",
    "\n",
    "\n",
    "plt.plot(dato,betaroll) #, ,color=my_cmap\n",
    "plt.plot(dato,betarollm, linestyle='--')\n",
    "plt.axvspan(betaroll.index[1258],betaroll.index[-1], facecolor='0.2', alpha=0.1)\n",
    "plt.legend(betaroll.columns,loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "plt.ylabel('Hedge ratio')\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(10, 5)\n",
    "plt.savefig('beta_rolls.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Net Cash position and number of trades\n",
    "netcash=pd.DataFrame(0, index=spreaddf.index, columns=['Cash position'])\n",
    "k=0\n",
    "for i in range(0,len(tradeinf.keys())):\n",
    "        if not tradeinf[spreaddf.columns[i]]:\n",
    "            k=1+k\n",
    "\n",
    "        else:\n",
    "            for j in range(0,len(tradeinf[spreaddf.columns[i]])):\n",
    "                netcash.iloc[tradeinf[spreaddf.columns[i]][j][4]:tradeinf[spreaddf.columns[i]][j][5],0]=netcash.iloc[tradeinf[spreaddf.columns[i]][j][4]:tradeinf[spreaddf.columns[i]][j][5],0]+tradeinf[spreaddf.columns[i]][j][1]\n",
    "    \n",
    "netcash['Total trades']=heinotrade.abs().sum(axis=1)\n",
    "\n",
    "#Tid hvor portefÃ¸ljen ikke er investeret\n",
    "1-(netcash['Total trades'] == 0).astype(int).sum()/df.index.get_loc('2019-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "fig.set_size_inches(10, 5)\n",
    "ax1.plot(dato, netcash.iloc[:,0]/100000, alpha=0.8)\n",
    "ax1.plot(dato, netcash.iloc[:,1], color='#08519c', alpha=0.8)\n",
    "ax2.plot(dato, bm.iloc[:,4], color='black', linewidth=1, linestyle=':')\n",
    "ax1.axvspan('2020-01-02', '2020-12-31', facecolor='0.2', alpha=0.1) #f'{value:,}'\n",
    "textstr = '\\n'.join((r'Average USD invested:  ' \"{0:,.0f}\".format(netcash.iloc[:,0].mean()),r'Average number of pair open: {%.2f}' % (netcash.iloc[:,1].mean())))\n",
    "ax1.text('2018-01-02', 10, textstr, fontsize=10, verticalalignment='top',bbox=dict(facecolor='none', edgecolor='black', pad=5, linewidth=0),linespacing = 1.5)\n",
    "fig.legend(['USD invested (100k)', '\\# pairs open','Out-of-sample','VIX (rh. axis)'], loc='upper right', bbox_to_anchor=(0.69, 0.8))\n",
    "fig.savefig('Cash_invested.pdf', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y360[11][11])\n",
    "print(x360[11][11])\n",
    "print(z360[11][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y180[11][11])\n",
    "print(x180[11][11])\n",
    "print(z180[11][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z360 = np.array([[tradegain(2,5,investigated,(1+i)/6,(2+i)/6+j/4) for i in range(0,20)] for j in range(0,20)])\n",
    "x360 = np.array([[(1+i)/6 for i in range(0,20)] for j in range(0,20)])\n",
    "y360= np.array([[(2+i)/6+j/4 for i in range(0,20)] for j in range(0,20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot different stop losses and std error bands for different \n",
    "fig = plt.figure()\n",
    "ax180 = fig.add_subplot(222, projection='3d')\n",
    "ax180.plot_surface(x180, y180, z180,cmap=cm.Blues, alpha=0.9)\n",
    "ax180.view_init(elev=0., azim=-90)\n",
    "ax180.set_ylabel('Stop loss')\n",
    "ax180.set_xlabel('Standard error band')\n",
    "#max180=np.unravel_index(np.argmax(z180), z180.shape)\n",
    "#ax180.plot(x180[max180[0]][max180[1]],y180[max180[0]][max180[1]],z180[max180[0]][max180[1]], markerfacecolor='r', markeredgecolor='r', marker='o', markersize=7)\n",
    "\n",
    "ax120 = fig.add_subplot(223, projection='3d')\n",
    "ax120.plot_surface(x120, y120, z120,cmap=cm.Blues, alpha=0.9)\n",
    "ax120.view_init(elev=0., azim=-90)\n",
    "ax120.set_ylabel('Stop loss')\n",
    "ax120.set_xlabel('Standard error band')\n",
    "\n",
    "ax80 = fig.add_subplot(224, projection='3d')\n",
    "ax80.plot_surface(x80, y80, z80,cmap=cm.Blues, alpha=0.9)\n",
    "ax80.view_init(elev=0, azim=-90)\n",
    "ax80.set_ylabel('Stop loss')\n",
    "ax80.set_xlabel('Standard error band')\n",
    "\n",
    "ax360 = fig.add_subplot(221, projection='3d')\n",
    "ax360.plot_surface(x360, y360, z360,cmap=cm.Blues, alpha=1)\n",
    "ax360.view_init(elev=0., azim=-90)\n",
    "ax360.set_ylabel('Stop loss')\n",
    "ax360.set_xlabel('Standard error band')\n",
    "\n",
    "ax180.set_title('(b)', y=-0.12)\n",
    "ax120.set_title('(c)', y=-0.12)\n",
    "ax80.set_title('(d)', y=-0.12)\n",
    "ax360.set_title('(a)', y=-0.12)\n",
    "plt.subplots_adjust(wspace=0.001, hspace=0.1)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "#plt.savefig('Boil_opt.pdf', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot different stop losses and std error bands for different \n",
    "fig = plt.figure()\n",
    "ax180 = fig.add_subplot(222, projection='3d')\n",
    "ax180.plot_surface(x180, y180, z180,cmap=cm.Blues, alpha=0.9)\n",
    "ax180.view_init(elev=0., azim=-90)\n",
    "ax180.set_xlabel('Standard error band')\n",
    "#max180=np.unravel_index(np.argmax(z180), z180.shape)\n",
    "#ax180.plot(x180[max180[0]][max180[1]],y180[max180[0]][max180[1]],z180[max180[0]][max180[1]], markerfacecolor='r', markeredgecolor='r', marker='o', markersize=7)\n",
    "\n",
    "ax120 = fig.add_subplot(223, projection='3d')\n",
    "ax120.plot_surface(x120, y120, z120,cmap=cm.Blues, alpha=0.9)\n",
    "ax120.view_init(elev=0., azim=-90)\n",
    "ax120.set_xlabel('Standard error band')\n",
    "\n",
    "ax80 = fig.add_subplot(224, projection='3d')\n",
    "ax80.plot_surface(x80, y80, z80,cmap=cm.Blues, alpha=0.9)\n",
    "ax80.view_init(elev=0, azim=-90)\n",
    "ax80.set_xlabel('Standard error band')\n",
    "\n",
    "ax360 = fig.add_subplot(221, projection='3d')\n",
    "ax360.plot_surface(x360, y360, z360,cmap=cm.Blues, alpha=1)\n",
    "ax360.view_init(elev=0., azim=-90)\n",
    "ax360.set_xlabel('Standard error band')\n",
    "\n",
    "ax180.set_title('(b)', y=-0.12)\n",
    "ax120.set_title('(c)', y=-0.12)\n",
    "ax80.set_title('(d)', y=-0.12)\n",
    "ax360.set_title('(a)', y=-0.12)\n",
    "plt.subplots_adjust(wspace=0.001, hspace=0.1)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "#plt.savefig('Boil_opt.pdf', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailylist=[]\n",
    "for i in range(0,daily_ret.shape[1]):\n",
    "    dailylist.append(daily_ret.iloc[:,i].values.tolist())\n",
    "\n",
    "dailylist = [item for sublist in dailylist for item in sublist]\n",
    "\n",
    "from itertools import compress\n",
    "bad_indices = np.isnan(pd.concat([bm.iloc[:len(daily_ret),0]]*len(pairs))) | np.isnan(dailylist)\n",
    "good_indices = ~bad_indices\n",
    "good_x = pd.concat([bm.iloc[:len(daily_ret),0]]*len(pairs))[good_indices]\n",
    "good_y = list(compress(dailylist,good_indices.values.tolist()))\n",
    "\n",
    "heatmap, xedges, yedges = np.histogram2d(good_x,good_y, bins=[120,250])\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(heatmap.T,cmap='binary',aspect='auto',extent=extent,origin='lower',vmin=0, vmax=50)\n",
    "plt.axvline(x=0,color='black')\n",
    "plt.hlines(0,xedges[0], xedges[-1],color='black')\n",
    "slope, intercept = np.polyfit(good_x, good_y, 1)\n",
    "plt.plot(good_x, good_x*slope + intercept, 'r', linewidth=0.1)\n",
    "plt.ylim(-4,4)\n",
    "plt.xlim(-4,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
